# 第17章

## 前沿

在本书中，我们试着将强化学习展现为一系列相关联的想法，而不是独立的方法。每个想法都可以视为其方法延伸的一个维度。这样的一系列维度贯穿了一个巨大的方法空间。在维度层面探索这个空间，我们期望获得有广度和深度的理解。本章中，我们会用方法空间中维度的概念，来概括我们在本书中已经陈述的一系列强化学习的观点，同时给出一些我们所囊括领域中的重要的分歧。

### 17.1 概览

本书中所有的强化学习方法有三个共同点。其一，目标都是估计值函数。其二，操作方法都是通过创建真实/可能状态轨迹上的值的副本。其三，都遵循着广义策略迭代（Generalized Policy Iteration,GPI）的主体策略。

